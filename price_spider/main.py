import os
import json
from typing import List, Dict
import concurrent.futures

from crawler.tiki_search import search as tiki
from crawler.lazada_search import search as lazada
from crawler.cellphone_search import search as cellphones
# DienMayXanh ƒë√£ t√°ch ra file ri√™ng crawl_dienmayxanh.py
# Shopee ƒë√£ t·∫Øt theo y√™u c·∫ßu

# C·∫•u h√¨nh s·ªë trang crawl v√† s·ªë worker song song (c√≥ th·ªÉ ch·ªânh qua env)
MAX_PAGES = int(os.getenv("CRAWL_MAX_PAGES", "50"))
MAX_WORKERS = int(os.getenv("CRAWL_MAX_WORKERS", "10"))  # Gi·∫£m ƒë·ªÉ tr√°nh qu√° t·∫£i

# Output files
JSONL_OUTPUT_FILE = r"C:\Users\letan\Downloads\SEG301\price_spider\data\products.jsonl"  # JSON Lines format

# D√πng ƒë·ªÉ ch·ªëng tr√πng (d·ª±a tr√™n platform v√† product_id)
seen_products = set()

def crawl_all(keyword):
    products = []

    crawlers = [
        ("Tiki", tiki),
        ("Lazada", lazada),
        ("Cellphone", cellphones),
        # Shopee ƒë√£ t·∫Øt
        # DienMayXanh ƒë√£ t√°ch ra file ri√™ng crawl_dienmayxanh.py
    ]
    
    # Create a wrapper to capture name
    def run_crawler(name, func, kw):
        print(f"[INFO] üöÄ Start Crawling {name}...")
        try:
            # ∆Øu ti√™n truy·ªÅn max_pages n·∫øu crawler h·ªó tr·ª£
            try:
                result = func(kw, max_pages=MAX_PAGES)
                # Ki·ªÉm tra k·∫øt qu·∫£
                if result is None:
                    print(f"[WARNING] ‚ö†Ô∏è {name}: Returned None")
                    return name, []
                if not isinstance(result, list):
                    print(f"[WARNING] ‚ö†Ô∏è {name}: Returned {type(result)}, expected list")
                    return name, []
                return name, result
            except TypeError as e:
                # Th·ª≠ kh√¥ng c√≥ max_pages
                try:
                    result = func(kw)
                    if result is None:
                        return name, []
                    if not isinstance(result, list):
                        return name, []
                    return name, result
                except Exception as e2:
                    print(f"[ERROR] ‚ùå {name}: TypeError fallback failed: {e2}")
                    import traceback
                    traceback.print_exc()
                    return name, e2
        except Exception as e:
            print(f"[ERROR] ‚ùå {name}: Exception occurred")
            import traceback
            traceback.print_exc()
            return name, e

    with concurrent.futures.ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:
        futures = [executor.submit(run_crawler, name, func, keyword) for name, func in crawlers]
        
        for future in concurrent.futures.as_completed(futures):
            name, result = future.result()
            if isinstance(result, Exception):
                print(f"[ERROR] ‚ùå {name}: {type(result).__name__}: {result}")
            elif isinstance(result, list):
                if len(result) > 0:
                    print(f"[OK] ‚úÖ {name}: {len(result)} items")
                    products.extend(result)
                else:
                    print(f"[WARNING] ‚ö†Ô∏è {name}: No items found (returned empty list)")
            else:
                print(f"[ERROR] ‚ùå {name}: Unexpected result type: {type(result)}")

    return products


def deduplicate_products(products: List[Dict]) -> List[Dict]:
    """Remove duplicate products based on platform and product_id"""
    seen = set()
    unique_products = []
    
    for product in products:
        # Create unique key from platform and product_id
        key = (product.get("platform", ""), product.get("product_id", ""))
        if key not in seen and key[0] and key[1]:  # Both must be non-empty
            seen.add(key)
            unique_products.append(product)
    
    return unique_products


def save_to_jsonl(products: List[Dict], append: bool = False):
    """
    Save products to JSONL format - t·ªëi ∆∞u t·ªëc ƒë·ªô
    """
    if not products:
        print("‚ö†Ô∏è Kh√¥ng c√≥ d·ªØ li·ªáu ƒë·ªÉ l∆∞u")
        return
    
    # Deduplicate
    products = deduplicate_products(products)
    
    def load_jsonl(path: str) -> List[Dict]:
        """Load JSONL nhanh v·ªõi buffering"""
        if not os.path.exists(path):
            return []
        data = []
        # S·ª≠ d·ª•ng buffering ƒë·ªÉ ƒë·ªçc nhanh h∆°n
        with open(path, "r", encoding="utf-8", buffering=8192) as f:
            for line in f:
                line = line.strip()
                if not line:
                    continue
                try:
                    data.append(json.loads(line))
                except:
                    continue
        return data
    
    # Load existing products if appending
    existing_products = load_jsonl(JSONL_OUTPUT_FILE) if append else []
    
    # Merge and deduplicate
    all_products = existing_products + products
    all_products = deduplicate_products(all_products)
    
    # Save as JSONL (JSON Lines format) - s·ª≠ d·ª•ng buffering ƒë·ªÉ ghi nhanh
    with open(JSONL_OUTPUT_FILE, "w", encoding="utf-8", buffering=8192) as f:
        for product in all_products:
            f.write(json.dumps(product, ensure_ascii=False) + "\n")
    
    print(f"üíæ Saved {len(all_products)} products ‚Üí {JSONL_OUTPUT_FILE}")


def main():
    print("===== E-COMMERCE PRICE SPIDER =====")

    while True:
        keyword = input("\nüëâ Nh·∫≠p t·ª´ kh√≥a s·∫£n ph·∫©m (Enter ƒë·ªÉ tho√°t): ").strip()

        if not keyword:
            print("üëã Tho√°t ch∆∞∆°ng tr√¨nh")
            break

        products = crawl_all(keyword)

        if not products:
            print("‚ö†Ô∏è Kh√¥ng crawl ƒë∆∞·ª£c d·ªØ li·ªáu")
            continue

        print(f"\n===== PREVIEW (First 3 items) =====")
        for i, product in enumerate(products[:3], 1):
            print(f"\n{i}. {product.get('platform', 'N/A')} - {product.get('product_name', 'N/A')[:50]}")
            print(f"   Price: {product.get('price', 0):,.0f}‚Ç´")
            if product.get('original_price'):
                print(f"   Original: {product.get('original_price', 0):,.0f}‚Ç´")
            if product.get('rating'):
                print(f"   Rating: {product.get('rating')} ({product.get('review_count', 0)} reviews)")
        
        print(f"\nNEW ITEMS: {len(products)}")
        
        # Save to JSON/JSONL
        save_to_jsonl(products, append=True)


if __name__ == "__main__":
    main()
